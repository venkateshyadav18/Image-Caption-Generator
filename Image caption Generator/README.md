# ðŸš€ IMAGE CAPTIONING WITH BLIP TRANSFORMER  

Welcome to **Image Captioning using BLIP** â€” an AI project that turns images into smart textual descriptions using a powerful vision-language transformer.

---

## ðŸŒ„ IMAGE CAPTION GENERATOR - Task 3  
**ðŸ”¬ Specialization:** *Artificial Intelligence*

---

## âœ¨ About This Project  

This project generates **natural language captions** from images using **Salesforce's BLIP (Bootstrapped Language-Image Pretraining)** model.  
The goal was to build a system that understands visuals and converts them into meaningful text â€” just like how humans describe a photo.  

I used the **Hugging Face Transformers** library along with **PIL** to load and process the image, and the model does the rest using powerful vision-to-text capabilities.

---

## ðŸ“œ Features  

- Upload an image and get a human-like caption  
- Based on **BLIP: Vision-Language Transformer**  
- Minimal, beginner-friendly Python code  
- Flexible for experimenting with different prompt styles  
- Clean and structured output ready for AI pipelines  

---

## ðŸ›  Tech Stack  

- **Python** â€“ for scripting  
- **Pillow (PIL)** â€“ to handle images  
- **Hugging Face Transformers** â€“ to load BLIP model  
- **Salesforce/blip-image-captioning-large** â€“ pre-trained model used

---

